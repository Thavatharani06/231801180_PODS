{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thavatharani06/231801180_PODS/blob/main/ex4(b).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcxvyWj2eFhm",
        "outputId": "a75714f0-1481-48e1-fbcb-cfb8458697c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Step 1 & 2: Setup\n",
        "!pip install spacy scikit-learn pandas --quiet\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load and Prepare Dataset\n",
        "\n",
        "print(\"\\nSTEP 3: Load and Prepare Dataset\")\n",
        "data = {\n",
        "    'Text': [\n",
        "        \"Absolutely wonderful - silky and sexy and comfortable.\",\n",
        "        \"Love this dress! it's sooo pretty.\",\n",
        "        \"I had to return it - the fit was just not right.\",\n",
        "        \"Terrible quality. Do not recommend.\",\n",
        "        \"Fast shipping and good packaging, but the product is bad.\",\n",
        "        \"The color is not the same as shown in the picture.\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original Dataset:\\n\", df, \"\\n\")\n",
        "\n",
        "# Step 3a: Remove missing records\n",
        "df.dropna(subset=['Text'], inplace=True)\n",
        "\n",
        "# Step 3b: Limit records\n",
        "df = df.head(1000)\n",
        "print(\"Cleaned Dataset (after removing missing):\\n\", df, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo1u8Y9ChYBj",
        "outputId": "9eed0207-b0ad-4b4c-eb68-3b65c1eeee55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 3: Load and Prepare Dataset\n",
            "Original Dataset:\n",
            "                                                 Text\n",
            "0  Absolutely wonderful - silky and sexy and comf...\n",
            "1                 Love this dress! it's sooo pretty.\n",
            "2   I had to return it - the fit was just not right.\n",
            "3                Terrible quality. Do not recommend.\n",
            "4  Fast shipping and good packaging, but the prod...\n",
            "5  The color is not the same as shown in the pict... \n",
            "\n",
            "Cleaned Dataset (after removing missing):\n",
            "                                                 Text\n",
            "0  Absolutely wonderful - silky and sexy and comf...\n",
            "1                 Love this dress! it's sooo pretty.\n",
            "2   I had to return it - the fit was just not right.\n",
            "3                Terrible quality. Do not recommend.\n",
            "4  Fast shipping and good packaging, but the prod...\n",
            "5  The color is not the same as shown in the pict... \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Preprocess Text Using spaCy\n",
        "\n",
        "print(\"STEP 4: Text Preprocessing using spaCy\")\n",
        "\n",
        "def spacy_preprocess(text):\n",
        "    print(f\"\\nOriginal Text: {text}\")\n",
        "    # a. Lowercase\n",
        "    text = text.lower()\n",
        "    print(\"a. Lowercased:\", text)\n",
        "\n",
        "    # b. Tokenize\n",
        "    doc = nlp(text)\n",
        "    print(\"b. Tokens:\", [token.text for token in doc])\n",
        "\n",
        "    # c. Filter out non-alpha\n",
        "    tokens = [token for token in doc if token.is_alpha]\n",
        "    print(\"c. Alphabetic Tokens:\", [t.text for t in tokens])\n",
        "\n",
        "    # d. Remove stopwords\n",
        "    tokens = [token for token in tokens if not token.is_stop]\n",
        "    print(\"d. Stopword Removed:\", [t.text for t in tokens])\n",
        "\n",
        "    # e. Lemmatize\n",
        "    lemmas = [token.lemma_ for token in tokens]\n",
        "    print(\"e. Lemmatized Tokens:\", lemmas)\n",
        "\n",
        "    # f. Join into final string\n",
        "    cleaned = ' '.join(lemmas)\n",
        "    print(\"f. Final Cleaned String:\", cleaned)\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "df['cleaned'] = df['Text'].apply(spacy_preprocess)\n",
        "\n",
        "print(\"\\nFinal Cleaned Dataset:\\n\", df[['Text', 'cleaned']], \"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTj0QK6ghk-6",
        "outputId": "d7f5d703-b4b3-49ac-f2d6-aa42c7e095ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 4: Text Preprocessing using spaCy\n",
            "\n",
            "Original Text: Absolutely wonderful - silky and sexy and comfortable.\n",
            "a. Lowercased: absolutely wonderful - silky and sexy and comfortable.\n",
            "b. Tokens: ['absolutely', 'wonderful', '-', 'silky', 'and', 'sexy', 'and', 'comfortable', '.']\n",
            "c. Alphabetic Tokens: ['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n",
            "d. Stopword Removed: ['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']\n",
            "e. Lemmatized Tokens: ['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']\n",
            "f. Final Cleaned String: absolutely wonderful silky sexy comfortable\n",
            "\n",
            "Original Text: Love this dress! it's sooo pretty.\n",
            "a. Lowercased: love this dress! it's sooo pretty.\n",
            "b. Tokens: ['love', 'this', 'dress', '!', 'it', \"'s\", 'sooo', 'pretty', '.']\n",
            "c. Alphabetic Tokens: ['love', 'this', 'dress', 'it', 'sooo', 'pretty']\n",
            "d. Stopword Removed: ['love', 'dress', 'sooo', 'pretty']\n",
            "e. Lemmatized Tokens: ['love', 'dress', 'sooo', 'pretty']\n",
            "f. Final Cleaned String: love dress sooo pretty\n",
            "\n",
            "Original Text: I had to return it - the fit was just not right.\n",
            "a. Lowercased: i had to return it - the fit was just not right.\n",
            "b. Tokens: ['i', 'had', 'to', 'return', 'it', '-', 'the', 'fit', 'was', 'just', 'not', 'right', '.']\n",
            "c. Alphabetic Tokens: ['i', 'had', 'to', 'return', 'it', 'the', 'fit', 'was', 'just', 'not', 'right']\n",
            "d. Stopword Removed: ['return', 'fit', 'right']\n",
            "e. Lemmatized Tokens: ['return', 'fit', 'right']\n",
            "f. Final Cleaned String: return fit right\n",
            "\n",
            "Original Text: Terrible quality. Do not recommend.\n",
            "a. Lowercased: terrible quality. do not recommend.\n",
            "b. Tokens: ['terrible', 'quality', '.', 'do', 'not', 'recommend', '.']\n",
            "c. Alphabetic Tokens: ['terrible', 'quality', 'do', 'not', 'recommend']\n",
            "d. Stopword Removed: ['terrible', 'quality', 'recommend']\n",
            "e. Lemmatized Tokens: ['terrible', 'quality', 'recommend']\n",
            "f. Final Cleaned String: terrible quality recommend\n",
            "\n",
            "Original Text: Fast shipping and good packaging, but the product is bad.\n",
            "a. Lowercased: fast shipping and good packaging, but the product is bad.\n",
            "b. Tokens: ['fast', 'shipping', 'and', 'good', 'packaging', ',', 'but', 'the', 'product', 'is', 'bad', '.']\n",
            "c. Alphabetic Tokens: ['fast', 'shipping', 'and', 'good', 'packaging', 'but', 'the', 'product', 'is', 'bad']\n",
            "d. Stopword Removed: ['fast', 'shipping', 'good', 'packaging', 'product', 'bad']\n",
            "e. Lemmatized Tokens: ['fast', 'shipping', 'good', 'packaging', 'product', 'bad']\n",
            "f. Final Cleaned String: fast shipping good packaging product bad\n",
            "\n",
            "Original Text: The color is not the same as shown in the picture.\n",
            "a. Lowercased: the color is not the same as shown in the picture.\n",
            "b. Tokens: ['the', 'color', 'is', 'not', 'the', 'same', 'as', 'shown', 'in', 'the', 'picture', '.']\n",
            "c. Alphabetic Tokens: ['the', 'color', 'is', 'not', 'the', 'same', 'as', 'shown', 'in', 'the', 'picture']\n",
            "d. Stopword Removed: ['color', 'shown', 'picture']\n",
            "e. Lemmatized Tokens: ['color', 'show', 'picture']\n",
            "f. Final Cleaned String: color show picture\n",
            "\n",
            "Final Cleaned Dataset:\n",
            "                                                 Text  \\\n",
            "0  Absolutely wonderful - silky and sexy and comf...   \n",
            "1                 Love this dress! it's sooo pretty.   \n",
            "2   I had to return it - the fit was just not right.   \n",
            "3                Terrible quality. Do not recommend.   \n",
            "4  Fast shipping and good packaging, but the prod...   \n",
            "5  The color is not the same as shown in the pict...   \n",
            "\n",
            "                                       cleaned  \n",
            "0  absolutely wonderful silky sexy comfortable  \n",
            "1                       love dress sooo pretty  \n",
            "2                             return fit right  \n",
            "3                   terrible quality recommend  \n",
            "4     fast shipping good packaging product bad  \n",
            "5                           color show picture   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Convert to TF-IDF\n",
        "\n",
        "print(\"STEP 5: Convert Reviews to TF-IDF Vectors\")\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['cleaned'])\n",
        "print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
        "print(\"TF-IDF Feature Names:\", vectorizer.get_feature_names_out(), \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96qjGjm0h0TT",
        "outputId": "f081f8c8-8e1d-41b9-806b-e9a7e661388a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: Convert Reviews to TF-IDF Vectors\n",
            "TF-IDF Matrix Shape: (6, 24)\n",
            "TF-IDF Feature Names: ['absolutely' 'bad' 'color' 'comfortable' 'dress' 'fast' 'fit' 'good'\n",
            " 'love' 'packaging' 'picture' 'pretty' 'product' 'quality' 'recommend'\n",
            " 'return' 'right' 'sexy' 'shipping' 'show' 'silky' 'sooo' 'terrible'\n",
            " 'wonderful'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6 & 7: Process Query and Get Matches\n",
        "def process_query(query, top_k=3):\n",
        "    print(f\"\\n\\nüîç Query: '{query}'\")\n",
        "\n",
        "    # Preprocess the query\n",
        "    cleaned_query = spacy_preprocess(query)\n",
        "    print(\"Preprocessed Query:\", cleaned_query)\n",
        "\n",
        "    # Convert to TF-IDF\n",
        "    query_vector = vectorizer.transform([cleaned_query])\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarity_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "\n",
        "    # Get top-k indices\n",
        "    top_indices = similarity_scores.argsort()[::-1][:top_k]\n",
        "    results = df.iloc[top_indices].copy()\n",
        "    results['Similarity Score'] = similarity_scores[top_indices]\n",
        "\n",
        "    print(\"\\nTop Matching Reviews:\")\n",
        "    return results[['Text', 'Similarity Score']]\n",
        "\n",
        "# example queries\n",
        "result1 = process_query(\"pretty and comfortable dress\", top_k=3)\n",
        "print(result1)\n",
        "\n",
        "result2 = process_query(\"bad quality product\", top_k=3)\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5MoI7mCh7sj",
        "outputId": "cde51585-ba89-4b8b-cd5e-cf8c24b982e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "üîç Query: 'pretty and comfortable dress'\n",
            "\n",
            "Original Text: pretty and comfortable dress\n",
            "a. Lowercased: pretty and comfortable dress\n",
            "b. Tokens: ['pretty', 'and', 'comfortable', 'dress']\n",
            "c. Alphabetic Tokens: ['pretty', 'and', 'comfortable', 'dress']\n",
            "d. Stopword Removed: ['pretty', 'comfortable', 'dress']\n",
            "e. Lemmatized Tokens: ['pretty', 'comfortable', 'dress']\n",
            "f. Final Cleaned String: pretty comfortable dress\n",
            "Preprocessed Query: pretty comfortable dress\n",
            "\n",
            "Top Matching Reviews:\n",
            "                                                Text  Similarity Score\n",
            "1                 Love this dress! it's sooo pretty.          0.577350\n",
            "0  Absolutely wonderful - silky and sexy and comf...          0.258199\n",
            "4  Fast shipping and good packaging, but the prod...          0.000000\n",
            "\n",
            "\n",
            "üîç Query: 'bad quality product'\n",
            "\n",
            "Original Text: bad quality product\n",
            "a. Lowercased: bad quality product\n",
            "b. Tokens: ['bad', 'quality', 'product']\n",
            "c. Alphabetic Tokens: ['bad', 'quality', 'product']\n",
            "d. Stopword Removed: ['bad', 'quality', 'product']\n",
            "e. Lemmatized Tokens: ['bad', 'quality', 'product']\n",
            "f. Final Cleaned String: bad quality product\n",
            "Preprocessed Query: bad quality product\n",
            "\n",
            "Top Matching Reviews:\n",
            "                                                Text  Similarity Score\n",
            "4  Fast shipping and good packaging, but the prod...          0.471405\n",
            "3                Terrible quality. Do not recommend.          0.333333\n",
            "5  The color is not the same as shown in the pict...          0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3dYUWd6iSOb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}